{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet"
      ],
      "metadata": {
        "id": "LRxDS_CEUiMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, LSTM, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "Q3myvmy90n1g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='TPRedesNeurais', config={'batch_size': 32})"
      ],
      "metadata": {
        "id": "AeUDRXQuUqJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txF8YP3uP3GU",
        "outputId": "9ad1b910-2494-4776-c0be-14e4c44a2867"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_files(folder_path, contador):\n",
        "    data = []\n",
        "    try:\n",
        "      for filename in os.listdir(folder_path):\n",
        "          if filename.endswith(\".json\"):\n",
        "              with open(os.path.join(folder_path, filename), 'r') as file:\n",
        "                  json_data = json.load(file)\n",
        "                  data.append(json_data)\n",
        "    except Exception as e:\n",
        "      print(f\"Error counting files in {folder_path+filename}: {e}\")\n",
        "      print(contador)\n",
        "      contador +=1\n",
        "    return data"
      ],
      "metadata": {
        "id": "AEcM0XF43t-G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_data = load_json_files('/content/drive/MyDrive/Faculdade/6o Periodo/outputs/train/pos', 0)\n",
        "train_neg_data = load_json_files('/content/drive/MyDrive/Faculdade/6o Periodo/outputs/train/neg', 0)\n",
        "\n",
        "test_pos_data = load_json_files('/content/drive/MyDrive/Faculdade/6o Periodo/outputs/test/pos', 0)\n",
        "test_neg_data = load_json_files('/content/drive/MyDrive/Faculdade/6o Periodo/outputs/test/neg', 0)"
      ],
      "metadata": {
        "id": "93KeBOyIngKH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_pos_data + train_neg_data\n",
        "test_data = test_pos_data + test_neg_data\n",
        "\n",
        "import random\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(test_data)"
      ],
      "metadata": {
        "id": "4OtQlANN4JUp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_data = train_pos_data + test_pos_data\n",
        "negative_data = train_neg_data + test_neg_data\n",
        "data = positive_data + negative_data\n",
        "\n",
        "import random\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "ev8GZRvBniym"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([item['sentence_embedding'] for item in data])\n",
        "y = np.array([item['label'] for item in data])\n",
        "\n",
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
      ],
      "metadata": {
        "id": "U6bFxP7in6sD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings = np.array([item['sentence_embedding'] for item in train_data])\n",
        "train_labels = np.array([item['label'] for item in train_data])\n",
        "\n",
        "test_embeddings = np.array([item['sentence_embedding'] for item in test_data])\n",
        "test_labels = np.array([item['label'] for item in test_data])"
      ],
      "metadata": {
        "id": "Pvrt88LjAmLQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (4096,)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Reshape((1, 4096), input_shape=input_shape),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    #tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "CJxIB5IOgiOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(4096,)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "3U_DqP_FyhWf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Wt4_SfIdAsOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='/content/drive/MyDrive/Faculdade/6o Periodo/model_architecture.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "1PF-1oJbylLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treino utilizando 50/50"
      ],
      "metadata": {
        "id": "vogoexMQBI_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_embeddings, train_labels, epochs=35, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "ZOt_W-PB_P2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation losses\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "202rWKTwvaq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_embeddings, test_labels)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "-HdRQKsy_bgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treino utilizando 80/20"
      ],
      "metadata": {
        "id": "aSNigjrmBMHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=35, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "_xmzYzj9vRzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation losses\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LLFfniyqveyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "9AJi110nLbK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = random.randint(0, len(test_data) - 1)\n",
        "sample_test_data = test_data[random_index]\n",
        "\n",
        "sample_test_embedding = np.array([sample_test_data['sentence_embedding']])\n",
        "\n",
        "prediction = model.predict(sample_test_embedding)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(\"Text:\", sample_test_data['text'])\n",
        "print(\"Sentence Embedding:\", sample_test_embedding.flatten())\n",
        "print(\"True Label:\", sample_test_data['label'])\n",
        "\n",
        "print(\"\\nModel Prediction:\")\n",
        "print(\"Predicted Probability:\", prediction.flatten())\n",
        "print(\"Predicted Label:\", int(round(prediction[0][0])))"
      ],
      "metadata": {
        "id": "iPPzzIXzLfMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}